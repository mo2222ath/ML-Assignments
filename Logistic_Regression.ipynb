{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdjd9GrJRuKj"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import rand\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self,X,Y,theta):\n",
        "      self.X = np.matrix(X.values)\n",
        "      self.Y = np.matrix(Y.values)\n",
        "      self.theta = np.matrix(np.zeros(self.X.shape[1]))\n",
        "      self.cost = []\n",
        "    \n",
        "    def sigmoid(self, z): return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def cost_function(self):                 \n",
        "        first = np.multiply(-self.Y, np.log(self.sigmoid(self.X * self.theta.T)))\n",
        "        second = np.multiply((1 - self.Y), np.log(1 - self.sigmoid(self.X * self.theta.T)))\n",
        "        return np.sum(first - second) / (len(self.X))\n",
        "\n",
        "    def fit(self ,epochs=25, lr=0.05):        \n",
        "        N = self.X.shape[0]\n",
        "        for _ in range(epochs):        \n",
        "            # Gradient Descent\n",
        "            y_pred = self.sigmoid(self.X * self.theta.T)\n",
        "            self.theta -= lr * (self.X.T * (y_pred - self.Y)).T / N            \n",
        "            self.cost.append(self.cost_function()) \n",
        "\n",
        "    def predict(self):        \n",
        "        z = self.X * self.theta.T\n",
        "        return [1 if i > 0.5 else 0 for i in self.sigmoid(z)]\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRMOKLs_3_RC",
        "outputId": "7cbdea65-ba21-4e88-ac7c-2d428d7ea6fb"
      },
      "source": [
        "heart_data = pd.read_csv(\"heart.csv\")\n",
        "\n",
        "heart_data = heart_data[['trestbps', 'chol', 'thalach', 'oldpeak','target']]\n",
        "\n",
        "Y = heart_data[['target']]\n",
        "\n",
        "heart_data = (heart_data - heart_data.mean()) / heart_data.std()\n",
        "\n",
        "X = heart_data.loc[:,['trestbps', 'chol', 'thalach', 'oldpeak']]\n",
        "\n",
        "cols = heart_data.shape[1]\n",
        "\n",
        "X = heart_data.iloc[:,0:cols-1]\n",
        "X.insert(0,'Ones' , 1)\n",
        "\n",
        "logisticModel = LogisticRegression(X,Y,theta)\n",
        "\n",
        "logisticModel.fit(100 , 0.5)\n",
        "\n",
        "print('cost : ',logisticModel.cost)\n",
        "print('theta :' ,logisticModel.theta)\n",
        "\n",
        "predictions = logisticModel.predict()\n",
        "\n",
        "correct = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 \n",
        "           for (a, b) in zip(predictions, logisticModel.Y)]\n",
        "\n",
        "print('number of correct is',sum(map(int, correct)) , 'from ' ,len(correct) )\n",
        "accuracy = (sum(map(int, correct)) / len(correct)) * 100\n",
        "print(accuracy , '%')\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost :  [0.6480628604663083, 0.6171985598181768, 0.5956994416509803, 0.5803972303604789, 0.5692733282913197, 0.5610317864254374, 0.5548238747024997, 0.5500806392234988, 0.5464117832584743, 0.5435437755580538, 0.5412811730719514, 0.5394818935828402, 0.5380410467231831, 0.536880133467717, 0.5359396876827367, 0.535174171031783, 0.5345483720439081, 0.5340348275071927, 0.5336119503479492, 0.5332626532603747, 0.5329733251428875, 0.5327330618878353, 0.5325330827469998, 0.5323662835911486, 0.5322268921836606, 0.5321102001927493, 0.5320123534329787, 0.5319301866483329, 0.5318610926219236, 0.531802917924002, 0.5317538794654444, 0.5317124973986035, 0.5316775409343918, 0.5316479844176533, 0.5316229715892535, 0.5316017864111046, 0.531583829174507, 0.5315685968783374, 0.5315556670706257, 0.5315446845089464, 0.5315353501223, 0.5315274118576837, 0.5315206570742899, 0.5315149062118485, 0.5315100075104802, 0.5315058326002825, 0.5315022728118145, 0.5314992360852828, 0.5314966443778649, 0.531494431486202, 0.531492541215476, 0.5314909258382424, 0.531489544795854, 0.5314883636032522, 0.5314873529244557, 0.531486487791491, 0.531485746943986, 0.5314851122703785, 0.5314845683347694, 0.5314841019760302, 0.5314837019679218, 0.5314833587307632, 0.5314830640867005, 0.531482811051866, 0.5314825936597807, 0.531482406811229, 0.531482246146578, 0.5314821079371376, 0.5314819889926803, 0.5314818865826889, 0.5314817983692612, 0.5314817223499292, 0.5314816568089064, 0.5314816002755074, 0.5314815514886706, 0.5314815093666779, 0.5314814729813027, 0.5314814415357267, 0.5314814143456773, 0.5314813908233011, 0.5314813704633815, 0.5314813528315472, 0.5314813375541879, 0.5314813243098225, 0.5314813128217103, 0.5314813028515235, 0.5314812941939264, 0.5314812866719314, 0.5314812801329166, 0.5314812744452123, 0.531481269495172, 0.5314812651846594, 0.5314812614288915, 0.531481258154586, 0.5314812552983699, 0.5314812528054128, 0.5314812506282511, 0.5314812487257773, 0.5314812470623693, 0.5314812456071443]\n",
            "theta : [[ 0.17627316 -0.1979738  -0.16207901  0.79600551 -0.82807511]]\n",
            "number of correct is 221 from  303\n",
            "72.93729372937293 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYgtpW1khGA6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}