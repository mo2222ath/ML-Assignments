{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2_decision_tree.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py1Fr9V-oaui"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import random\r\n",
        "from pprint import pprint\r\n"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1oxLoqQpavc"
      },
      "source": [
        "def train_test_split(df, size):\r\n",
        "    \r\n",
        "    if isinstance(size, float):\r\n",
        "        size = round(size * len(df))\r\n",
        "\r\n",
        "    indices = df.index.tolist()\r\n",
        "    test_indices = random.sample(population=indices, k=size)\r\n",
        "\r\n",
        "    train_df = df.loc[test_indices]\r\n",
        "    test_df = df.drop(test_indices)\r\n",
        "    \r\n",
        "    return train_df, test_df"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W6_5Fb7sedt"
      },
      "source": [
        "def check_purity(data):\r\n",
        "    \r\n",
        "    label_column = data[:, -1]\r\n",
        "    unique_classes = np.unique(label_column)\r\n",
        "\r\n",
        "    if len(unique_classes) == 1:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xJy_6DWssY0"
      },
      "source": [
        "def classify_data(data):\r\n",
        "    \r\n",
        "    label_column = data[:, -1]\r\n",
        "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\r\n",
        "\r\n",
        "    index = counts_unique_classes.argmax()\r\n",
        "    classification = unique_classes[index]\r\n",
        "    \r\n",
        "    return classification"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEyJXOK7tfrV"
      },
      "source": [
        "def get_potential_splits(data):\r\n",
        "    \r\n",
        "    potential_splits = {}\r\n",
        "    _, n_columns = data.shape\r\n",
        "    for column_index in range(n_columns - 1):          # excluding the last column which is the label\r\n",
        "        values = data[:, column_index]\r\n",
        "        unique_values = np.unique(values)\r\n",
        "        \r\n",
        "        potential_splits[column_index] = unique_values\r\n",
        "    \r\n",
        "    return potential_splits"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIGydgDbuBYj"
      },
      "source": [
        "def split_data(data, split_column, split_value):\r\n",
        "    \r\n",
        "    split_column_values = data[:, split_column]\r\n",
        "\r\n",
        "    # features are categorical   \r\n",
        "    data_below = data[split_column_values == split_value]\r\n",
        "    data_above = data[split_column_values != split_value]\r\n",
        "    \r\n",
        "    return data_below, data_above"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUova4KsvHOG"
      },
      "source": [
        "def calculate_entropy(data):\r\n",
        "    \r\n",
        "    label_column = data[:, -1]\r\n",
        "    _, counts = np.unique(label_column, return_counts=True)\r\n",
        "\r\n",
        "    probabilities = counts / counts.sum()\r\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\r\n",
        "     \r\n",
        "    return entropy"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X36kYuWgwTo6"
      },
      "source": [
        "def calculate_overall_entropy(data_below, data_above):\r\n",
        "    \r\n",
        "    n = len(data_below) + len(data_above)\r\n",
        "    p_data_below = len(data_below) / n\r\n",
        "    p_data_above = len(data_above) / n\r\n",
        "\r\n",
        "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \r\n",
        "                      + p_data_above * calculate_entropy(data_above))\r\n",
        "    \r\n",
        "    return overall_entropy"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b56zCQwMw-Wv"
      },
      "source": [
        "def determine_best_split(data, potential_splits):\r\n",
        "    \r\n",
        "    overall_entropy = 9999\r\n",
        "    for column_index in potential_splits:\r\n",
        "        for value in potential_splits[column_index]:\r\n",
        "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\r\n",
        "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\r\n",
        "\r\n",
        "            if current_overall_entropy <= overall_entropy:\r\n",
        "                overall_entropy = current_overall_entropy\r\n",
        "                best_split_column = column_index\r\n",
        "                best_split_value = value\r\n",
        "    \r\n",
        "    return best_split_column, best_split_value"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYRhLnyFxZg4"
      },
      "source": [
        "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5):\r\n",
        "    \r\n",
        "    # data preparations\r\n",
        "    if counter == 0:\r\n",
        "        global COLUMN_HEADERS\r\n",
        "        COLUMN_HEADERS = df.columns\r\n",
        "        data = df.values\r\n",
        "    else:\r\n",
        "        data = df           \r\n",
        "    \r\n",
        "    \r\n",
        "    # base cases\r\n",
        "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\r\n",
        "        classification = classify_data(data)\r\n",
        "        \r\n",
        "        return classification\r\n",
        "\r\n",
        "    \r\n",
        "    # recursive part\r\n",
        "    else:    \r\n",
        "        counter += 1\r\n",
        " \r\n",
        "        potential_splits = get_potential_splits(data)\r\n",
        "        split_column, split_value = determine_best_split(data, potential_splits)\r\n",
        "        data_below, data_above = split_data(data, split_column, split_value)\r\n",
        "        \r\n",
        "        # check for empty data\r\n",
        "        if len(data_below) == 0 or len(data_above) == 0:\r\n",
        "            classification = classify_data(data)\r\n",
        "            return classification\r\n",
        "        \r\n",
        "        # determine question\r\n",
        "        feature_name = COLUMN_HEADERS[split_column]   \r\n",
        "        question = \"{} = {}\".format(feature_name, split_value)\r\n",
        "        \r\n",
        "        # instantiate sub-tree\r\n",
        "        sub_tree = {question: []}\r\n",
        "        \r\n",
        "        # find answers (recursion)\r\n",
        "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\r\n",
        "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\r\n",
        "        \r\n",
        "        # If the answers are the same, then there is no point in asking the qestion.\r\n",
        "        # This could happen when the data is classified even though it is not pure\r\n",
        "        # yet (min_samples or max_depth base case).\r\n",
        "        if yes_answer == no_answer:\r\n",
        "            sub_tree = yes_answer\r\n",
        "        else:\r\n",
        "            sub_tree[question].append(yes_answer)\r\n",
        "            sub_tree[question].append(no_answer)\r\n",
        "        \r\n",
        "        return sub_tree"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jlqQUfSExlO"
      },
      "source": [
        "def classify_example(example, tree):\r\n",
        "    question = list(tree.keys())[0]\r\n",
        "    feature_name, comparison_operator, value = question.split(\" \")\r\n",
        "\r\n",
        "    # ask question\r\n",
        "    \r\n",
        "    if example[int(feature_name)] == value:\r\n",
        "        answer = tree[question][0]\r\n",
        "    else:\r\n",
        "        answer = tree[question][1]\r\n",
        "\r\n",
        "    # base case\r\n",
        "    if not isinstance(answer, dict):\r\n",
        "        return answer\r\n",
        "    \r\n",
        "    # recursive part\r\n",
        "    else:\r\n",
        "        residual_tree = answer\r\n",
        "        return classify_example(example, residual_tree)"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAYOhEfyE5kg"
      },
      "source": [
        "def calculate_accuracy(df, tree):\r\n",
        "\r\n",
        "    df[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\r\n",
        "    df[\"classification_correct\"] = df[\"classification\"] == df[\"lable\"]\r\n",
        "    \r\n",
        "    accuracy = df[\"classification_correct\"].mean()\r\n",
        "    \r\n",
        "    return accuracy"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DReuzHKl1gHh",
        "outputId": "5fe70902-6097-4ac8-e1b8-92a51e8e6375"
      },
      "source": [
        "df = pd.read_csv(\"house-votes.csv\" ,header=None)\r\n",
        "lable = df[0]\r\n",
        "df = df.drop(0,axis=1)\r\n",
        "df['lable'] = lable \r\n",
        "df.head()\r\n",
        "\r\n",
        "for i in range(1 , len(df.columns) - 1):\r\n",
        "  mode = df[i].mode()[0]\r\n",
        "  df = df.replace('?', mode)\r\n",
        "\r\n",
        "# random.seed(0)\r\n",
        "# train_df, test_df = train_test_split(df,20)\r\n",
        "\r\n",
        "# tree = decision_tree_algorithm(train_df, max_depth=7)\r\n",
        "# pprint(tree)\r\n",
        "\r\n",
        "# # example = test_df.iloc[2]\r\n",
        "# # example\r\n",
        "\r\n",
        "# accuracy = calculate_accuracy(test_df, tree)\r\n",
        "# accuracy"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'4 = y': [{'3 = y': [{'16 = y': ['republican', 'democrat']}, 'republican']},\n",
            "           {'8 = y': ['democrat', {'9 = y': ['democrat', 'republican']}]}]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8939759036144578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANjHAQ0PFTW_"
      },
      "source": [
        "def experimentSplitsData(data , trainSize):\r\n",
        "  experiments = []\r\n",
        "  for i in range(5):\r\n",
        "    # random.seed(i)\r\n",
        "    train_df, _ = train_test_split(df,trainSize)\r\n",
        "    tree = decision_tree_algorithm(train_df, max_depth=8)\r\n",
        "    accuracy = calculate_accuracy(test_df, tree)\r\n",
        "    experiments.append((trainSize , accuracy))\r\n",
        "  return experiments\r\n"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOajcE5cKYME",
        "outputId": "074e84d8-1e34-4896-ab98-126c8a52e691"
      },
      "source": [
        "train_sizes = [0.25 , 0.30 , 0.40 , 0.50 , 0.60 , 0.70]\r\n",
        "experiments = []\r\n",
        "for train_size in train_sizes:\r\n",
        "  experiments.append(experimentSplitsData(df,train_size))\r\n",
        "\r\n",
        "experiments"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0.25, 0.946987951807229),\n",
              "  (0.25, 0.9686746987951808),\n",
              "  (0.25, 0.963855421686747),\n",
              "  (0.25, 0.9566265060240964),\n",
              "  (0.25, 0.9734939759036144)],\n",
              " [(0.3, 0.9590361445783132),\n",
              "  (0.3, 0.9614457831325302),\n",
              "  (0.3, 0.9493975903614458),\n",
              "  (0.3, 0.963855421686747),\n",
              "  (0.3, 0.9710843373493976)],\n",
              " [(0.4, 0.9662650602409638),\n",
              "  (0.4, 0.9710843373493976),\n",
              "  (0.4, 0.9686746987951808),\n",
              "  (0.4, 0.9710843373493976),\n",
              "  (0.4, 0.9686746987951808)],\n",
              " [(0.5, 0.9759036144578314),\n",
              "  (0.5, 0.944578313253012),\n",
              "  (0.5, 0.9710843373493976),\n",
              "  (0.5, 0.9759036144578314),\n",
              "  (0.5, 0.963855421686747)],\n",
              " [(0.6, 0.9759036144578314),\n",
              "  (0.6, 0.9855421686746988),\n",
              "  (0.6, 0.9783132530120482),\n",
              "  (0.6, 0.983132530120482),\n",
              "  (0.6, 0.9855421686746988)],\n",
              " [(0.7, 0.983132530120482),\n",
              "  (0.7, 0.9879518072289156),\n",
              "  (0.7, 0.980722891566265),\n",
              "  (0.7, 0.9855421686746988),\n",
              "  (0.7, 0.9855421686746988)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onRI1psYOZhs"
      },
      "source": [
        ""
      ],
      "execution_count": 231,
      "outputs": []
    }
  ]
}